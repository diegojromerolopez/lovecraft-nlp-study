{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple generation of random text based in bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft = nltk.corpus.PlaintextCorpusReader(\"lovecraft\", \".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_model_from_max_probable_word(cfdist, word, num=15):\n",
    "    words = [word]\n",
    "    for i in range(num):\n",
    "        word = cfdist[word].max()\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_random_word_from_fd(fd):\n",
    "    # Construct probabilities for each word that belongs to the frequency distribution\n",
    "    word_prob_pairs = [(word_i,word_i_freq/fd.N()) for word_i,word_i_freq in fd.items()]\n",
    "    words = [word_prob_pair[0] for word_prob_pair in word_prob_pairs]\n",
    "    probabilities = [word_prob_pair[1] for word_prob_pair in word_prob_pairs]\n",
    "\n",
    "    # Select a random chose according to the probabilities of each word\n",
    "    random_word_chose = np.random.multinomial(1, probabilities)\n",
    "    random_word_index = list(random_word_chose).index(1)\n",
    "    return words[random_word_index]\n",
    "\n",
    "\n",
    "def generate_model_from_word(cfdist, word, num=15):\n",
    "    words = []\n",
    "    for i in range(num):\n",
    "        words.append(word)\n",
    "        word_fd = cfdist[word]\n",
    "        word = get_random_word_from_fd(word_fd)\n",
    "    return words\n",
    "\n",
    "\n",
    "def generate_model(cfdist, fd, num=15):\n",
    "    words = []\n",
    "    word = get_random_word_from_fd(fd)\n",
    "        \n",
    "    for i in range(num):\n",
    "        words.append(word)\n",
    "        word_fd = cfdist[word]\n",
    "        word = get_random_word_from_fd(word_fd)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all non-alphabetic words (numbers, punctuation symbols, etc.).\n",
    "text = [word for word in lovecraft.words() if word.isalpha()]\n",
    "\n",
    "# Get all bigrams of the text (bigrams are pairs of words that appears in the text)\n",
    "bigrams = nltk.bigrams(text)\n",
    "\n",
    "# Compute their conditional frequency for each word\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "# Compute the frequency (number of appearances of each word)\n",
    "fd = nltk.FreqDist(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution:\n",
      "\n",
      "['Cthulhu', 'R', 'lyehian', 'which', 'were', 'many', 'of', 'one', 'ever', 'saw', 'that', 'I', 'am', 'crazy', 'things', 'which', 'atoned', 'for', 'this', 'abhorred', 'and', 'down', 'the', 'stony', 'cliff', 'the', 'companionship', 'of', 'its', 'outlines', 'of', 'suction', 'With', 'Sunne', 'in', 'Greek', 'inscription', 'above', 'the', 'high', 'rock', 'when', 'we', 'floated', 'from', 'shots', 'broke', 'off', 'the', 'James', 'Manning', 'was', 'a', 'white', 'fungous', 'growths', 'predominated', 'some', 'day', 'you', 'were', 'like', 'the', 'South', 'who', 'assisted', 'in', 'the', 'early', 'existence', 'At', 'twenty', 'seventh', 'of', 'the', 'creaking', 'sound', 'of', 'the', 'solution', 'was', 'said', 'but', 'the', 'Gugs', 'kingdom', 'would', 'be', 'made', 'Asenath', 's', 'more', 'The', 'living', 'denizen', 'of', 'any', 'known', 'till', 'it', 'Drawing', 'inside', 'coat', 'lapel', 'and', 'was', 'a', 'notably', 'ferns', 'calamites', 'whose', 'windings', 'of', 'the', 'torture', 'myself', 'and', 'means', 'as', 'little', 'windows', 'at', 'face', 'that', 'you', 'at', 'the', 'library', 'of', 'her', 'I', 'saw', 'the', 'most', 'of', 'their', 'linkage', 'of', 'the', 'vegetation', 'in', 'William', 'J', 'C', 'IVLIVS', 'VERVS', 'MAXIMINVS', 'THE', 'NAMELESS', 'CITY', 'When', 'it', 'was', 'a', 'development', 'occurred', 'and', 'confront', 'the', 'pastures', 'bright', 'again', 'what', 'the', 'lowest', 'level', 'forming', 'and', 'paint', 'and', 'that', 'ain', 't', 'answer', 'for', 'nearly', 'half', 'hide', 'from', 'afar', 'the', 'seat', 'of', 'wind', 'for', 'much', 'sense', 'I', 'will', 'About', 'this', 'van', 'loaded', 'We', 'meant', 'no', 'longer', 'be', 'by', 'the']\n",
      "\n",
      "\n",
      "\n",
      "Generate 200 words based on the max probability of the next word:\n",
      "\n",
      "['Cthulhu', 'fhtagn', 'This', 'was', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution\n",
    "random_words = generate_model_from_word(cfd, \"Cthulhu\", num=200)\n",
    "\n",
    "# Generate 200 words based on the max probability of the next word\n",
    "random_text_with_max_probability = generate_model_from_max_probable_word(cfd, \"Cthulhu\", num=200)\n",
    "\n",
    "print(\"Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution:\\n\\n{}\\n\\n\\n\".format(random_words))\n",
    "\n",
    "print(\"Generate 200 words based on the max probability of the next word:\\n\\n{}\\n\\n\\n\".format(random_text_with_max_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the type of words of each word\n",
    "def format_random_text(generated_words):\n",
    "    generated_tagged_words = nltk.tag.pos_tag(generated_words)\n",
    "    word_type = dict(generated_tagged_words)\n",
    "\n",
    "    # Add a \".\" before each capital letter that is not a proper name or \"I\"\n",
    "    text = \"\"\n",
    "    for i in range(0, len(list(generated_words))):\n",
    "        if i >= len(list(generated_words)) - 1:\n",
    "            text += \" \"+generated_words[i]+\".\"\n",
    "        else:\n",
    "            text += \" \"+generated_words[i] + (\".\" if generated_words[i+1][0].isupper() and word_type.get(generated_words[i+1]) not in (\"NNP\", \"POS\") and generated_words[i+1] != \"I\" else \"\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 200 word text selecting each time a random word from the next possible ones acccording to its probability distribution:\n",
      "\n",
      "Cthulhu R lyehian which were many of one ever saw that I am crazy things which atoned for this abhorred and down the stony cliff the companionship of its outlines of suction. With Sunne in Greek inscription above the high rock when we floated from shots broke off the James Manning was a white fungous growths predominated some day you were like the South who assisted in the early existence. At twenty seventh of the creaking sound of the solution was said but the Gugs kingdom would be made Asenath s more. The living denizen of any known till it Drawing inside coat lapel and was a notably ferns calamites whose windings of the torture myself and means as little windows at face that you at the library of her I saw the most of their linkage of the vegetation in William J C IVLIVS VERVS MAXIMINVS THE NAMELESS CITY. When it was a development occurred and confront the pastures bright again what the lowest level forming and paint and that ain t answer for nearly half hide from afar the seat of wind for much sense I will. About this van loaded. We meant no longer be by the.\n",
      "\n",
      "\n",
      "\n",
      "Generate 200 words based on the max probability of the next word:\n",
      "\n",
      "Cthulhu fhtagn. This was a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "print(\"Generate 200 word text selecting each time a random word from the next possible ones acccording to its probability distribution:\\n\\n{}\\n\\n\\n\".format(format_random_text(random_words)))\n",
    "\n",
    "print(\"Generate 200 words based on the max probability of the next word:\\n\\n{}\\n\\n\\n\".format(format_random_text(random_text_with_max_probability)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
