{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple generation of random text based in bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft = nltk.corpus.PlaintextCorpusReader(\"lovecraft\", \".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_model_from_max_probable_word(cfdist, word, num=15):\n",
    "    words = [word]\n",
    "    for i in range(num):\n",
    "        word = cfdist[word].max()\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_random_word_from_fd(fd):\n",
    "    # Construct probabilities for each word that belongs to the frequency distribution\n",
    "    word_prob_pairs = [(word_i,word_i_freq/fd.N()) for word_i,word_i_freq in fd.items()]\n",
    "    words = [word_prob_pair[0] for word_prob_pair in word_prob_pairs]\n",
    "    probabilities = [word_prob_pair[1] for word_prob_pair in word_prob_pairs]\n",
    "\n",
    "    # Select a random chose according to the probabilities of each word\n",
    "    random_word_chose = np.random.multinomial(1, probabilities)\n",
    "    random_word_index = list(random_word_chose).index(1)\n",
    "    return words[random_word_index]\n",
    "\n",
    "\n",
    "def generate_model_from_word(cfdist, word, num=15):\n",
    "    words = []\n",
    "    for i in range(num):\n",
    "        words.append(word)\n",
    "        word_fd = cfdist[word]\n",
    "        word = get_random_word_from_fd(word_fd)\n",
    "    return words\n",
    "\n",
    "\n",
    "def generate_model(cfdist, fd, num=15):\n",
    "    words = []\n",
    "    word = get_random_word_from_fd(fd)\n",
    "        \n",
    "    for i in range(num):\n",
    "        words.append(word)\n",
    "        word_fd = cfdist[word]\n",
    "        word = get_random_word_from_fd(word_fd)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all non-alphabetic words (numbers, punctuation symbols, etc.).\n",
    "text = [word for word in lovecraft.words() if word.isalpha()]\n",
    "\n",
    "# Get all bigrams of the text (bigrams are pairs of words that appears in the text)\n",
    "bigrams = nltk.bigrams(text)\n",
    "\n",
    "# Compute their conditional frequency for each word\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "# Compute the frequency (number of appearances of each word)\n",
    "fd = nltk.FreqDist(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution:\n",
      "\n",
      "['Cthulhu', 'still', 'be', 'that', 'the', 'investigations', 'Late', 'in', 'a', 'comets', 'suns', 'and', 'cut', 'from', 'the', 'lake', 'itself', 'into', 'that', 'if', 'as', 'loudly', 'and', 'Atal', 'was', 'then', 'jest', 'then', 'remain', 'as', 'low', 'sun', 'rose', 'and', 'had', 'predicted', 'that', 'these', 'men', 'have', 'said', 'so', 'sensationally', 'reported', 'seeing', 'hearing', 'voices', 'in', 'the', 'crowd', 'fancied', 'that', 'which', 'I', 'spent', 'and', 'with', 'their', 'more', 'than', 'Mr', 'Brown', 'amp', 'O', 'course', 'determined', 'to', 'find', 'the', 'great', 'problem', 'is', 'not', 'any', 'message', 'came', 'to', 'divert', 'my', 'talk', 'of', 'chemicals', 'which', 'I', 'fled', 'from', 'things', 'in', 'the', 'decayed', 'louvre', 'boarded', 'up', 'paper', 'Kuranes', 'was', 'less', 'explicable', 'by', 'another', 'bulletin', 'announced', 'the', 'same', 'things', 'that', 'in', 'for', 'the', 'cliff', 'as', 'brought', 'from', 'Nahum', 's', 'death', 'of', 'the', 'witch', 's', 'books', 'ranged', 'along', 'deserted', 'brick', 'blocks', 'loose', 'upon', 'the', 'rest', 'tall', 'lighthouse', 'keeper', 'of', 'it', 'until', 'one', 'of', 'Celephais', 'in', 'the', 'horror', 'was', 'frankly', 'that', 'others', 'Viscous', 'obstacles', 'It', 'was', 'a', 'frontage', 'of', 'a', 'frenzied', 'and', 'were', 'unnerving', 'influence', 'I', 'knew', 'held', 'a', 'thing', 'he', 'feared', 'for', 'the', 'phonograph', 'dictaphone', 'attachment', 'for', 'almost', 'faded', 'into', 'which', 'caused', 'him', 'a', 'droning', 'of', 'Olathoe', 'in', 'the', 'captains', 'and', 'had', 'ever', 'known', 'as', 'the', 'Memphian', 'cemeteries', 'were', 'sullen', 'mood', 'in', 'panic', 'and', 'disclosing']\n",
      "\n",
      "\n",
      "\n",
      "Generate 200 words based on the max probability of the next word:\n",
      "\n",
      "['Cthulhu', 'fhtagn', 'This', 'was', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the', 'old', 'man', 's', 'a', 'great', 'stone', 'and', 'the']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution\n",
    "random_words = generate_model_from_word(cfd, \"Cthulhu\", num=200)\n",
    "\n",
    "# Generate 200 words based on the max probability of the next word\n",
    "random_text_with_max_probability = generate_model_from_max_probable_word(cfd, \"Cthulhu\", num=200)\n",
    "\n",
    "print(\"Generate 200 words selecting each time a random word from the next possible ones acccording to its probability distribution:\\n\\n{}\\n\\n\\n\".format(random_words))\n",
    "\n",
    "print(\"Generate 200 words based on the max probability of the next word:\\n\\n{}\\n\\n\\n\".format(random_text_with_max_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the type of words of each word\n",
    "def format_random_text(generated_words):\n",
    "    generated_tagged_words = nltk.tag.pos_tag(generated_words)\n",
    "    word_type = dict(generated_tagged_words)\n",
    "\n",
    "    # Add a \".\" before each capital letter that is not a proper name or \"I\"\n",
    "    text = \"\"\n",
    "    for i in range(0, len(list(generated_words))):\n",
    "        if i >= len(list(generated_words)) - 1:\n",
    "            text += \" \"+generated_words[i]+\".\"\n",
    "        else:\n",
    "            text += \" \"+generated_words[i] + (\".\" if generated_words[i+1][0].isupper() and word_type.get(generated_words[i+1]) not in (\"NNP\", \"POS\") and generated_words[i+1] != \"I\" else \"\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 200 word text selecting each time a random word from the next possible ones acccording to its probability distribution:\n",
      "\n",
      "Cthulhu still be that the investigations Late in a comets suns and cut from the lake itself into that if as loudly and Atal was then jest then remain as low sun rose and had predicted that these men have said so sensationally reported seeing hearing voices in the crowd fancied that which I spent and with their more than Mr Brown amp O course determined to find the great problem is not any message came to divert my talk of chemicals which I fled from things in the decayed louvre boarded up paper Kuranes was less explicable by another bulletin announced the same things that in for the cliff as brought from Nahum s death of the witch s books ranged along deserted brick blocks loose upon the rest tall lighthouse keeper of it until one of Celephais in the horror was frankly that others. Viscous obstacles. It was a frontage of a frenzied and were unnerving influence I knew held a thing he feared for the phonograph dictaphone attachment for almost faded into which caused him a droning of Olathoe in the captains and had ever known as the. Memphian cemeteries were sullen mood in panic and disclosing.\n",
      "\n",
      "\n",
      "\n",
      "Generate 200 words based on the max probability of the next word:\n",
      "\n",
      "Cthulhu fhtagn. This was a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the old man s a great stone and the.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "print(\"Generate 200 word text selecting each time a random word from the next possible ones acccording to its probability distribution:\\n\\n{}\\n\\n\\n\".format(format_random_text(random_words)))\n",
    "\n",
    "print(\"Generate 200 words based on the max probability of the next word:\\n\\n{}\\n\\n\\n\".format(format_random_text(random_text_with_max_probability)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
