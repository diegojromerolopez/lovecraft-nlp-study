{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is generate more common sentences according to their word tagging. So the sentences will have the real structure written by lovecraft and composed by a list of most common words in that kind of sentence.\n",
    "\n",
    "The result should be a somewhat real phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft = nltk.corpus.PlaintextCorpusReader(\"lovecraft\", \".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedWord(object):\n",
    "    \n",
    "    def __init__(self, words, count):\n",
    "        self.word_hash = {}\n",
    "        self.words = words\n",
    "        self.count = count\n",
    "        index = 0\n",
    "        for word in words:\n",
    "            self.word_hash[word] = index\n",
    "            index += 1\n",
    "\n",
    "    def update(self, word):\n",
    "        word_index = self.word_hash.get(word)\n",
    "        if word_index is not None:\n",
    "            self.count[word_index] += 1\n",
    "        else:\n",
    "            self.words.append(word)\n",
    "            self.count.append(1)\n",
    "            word_index = len(self.words) - 1\n",
    "            self.word_hash[word] = word_index\n",
    "    \n",
    "    def get_random(self, seed):\n",
    "        np.random.seed(seed=seed)\n",
    "        total_count = sum(self.count)\n",
    "        probabilities = [word_count/total_count for word_count in self.count]\n",
    "        random_word_chose = np.random.multinomial(1, probabilities)\n",
    "        random_word_index = list(random_word_chose).index(1)\n",
    "        return self.words[random_word_index]\n",
    "\n",
    "\n",
    "class Sentence(object):\n",
    "    \n",
    "    def __init__(self, words, tags):\n",
    "        self.tags = tags\n",
    "        self.words = []\n",
    "        for word in words:\n",
    "            self.words.append(TaggedWord(words=[word.lower()], count=[1]))\n",
    "        \n",
    "    def update(self, words):\n",
    "        word_index = 0\n",
    "        for word in words:\n",
    "            self.words[word_index].update(word.lower())\n",
    "            word_index += 1\n",
    "    \n",
    "    def generate(self, seed):\n",
    "        return [word.get_random(seed) for word in self.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft_sentences = lovecraft.sents()\n",
    "sentences = {}\n",
    "sentence_count = defaultdict(int)\n",
    "for tokenized_sentence in lovecraft_sentences:\n",
    "    sentence_with_tagged_words = nltk.pos_tag(tokenized_sentence)\n",
    "    \n",
    "    sentence_words = list(zip(*sentence_with_tagged_words))[0]\n",
    "    sentence_tags = list(zip(*sentence_with_tagged_words))[1]\n",
    "    \n",
    "    sentence_checksum = \"-\".join(sentence_tags)\n",
    "    \n",
    "    if sentence_checksum in sentences:\n",
    "        sentences[sentence_checksum].update(sentence_words)\n",
    "    else:\n",
    "        sentences[sentence_checksum] = Sentence(words=sentence_words, tags=sentence_tags)\n",
    "    \n",
    "    sentence_count[sentence_checksum] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'bus', ',', 'rather', 'early', ',', 'rattled', 'in', 'with', 'three', 'passengers', 'somewhat', 'before', 'eight', ',', 'and', 'an', 'evil', '-', 'looking', 'fellow', 'on', 'the', 'sidewalk', 'muttered', 'a', 'few', 'indistinguishable', 'words', 'to', 'the', 'driver', '.']\n",
      "['there', 'seemed', 'virtually', 'nothing', 'to', 'do', 'to', 'calm', 'them', ',', 'and', 'when', 'nahum', 'opened', 'the', 'stable', 'door', 'they', 'all', 'bolted', 'out', 'like', 'frightened', 'woodland', 'deer', '.']\n",
      "['there', 'seemed', 'virtually', 'nothing', 'to', 'do', 'to', 'calm', 'them', ',', 'and', 'when', 'nahum', 'opened', 'the', 'stable', 'door', 'they', 'all', 'bolted', 'out', 'like', 'frightened', 'woodland', 'deer', '.']\n"
     ]
    }
   ],
   "source": [
    "total_count = sum(sentence_count.values())\n",
    "sentence_tags = [_sentence_tags for _sentence_tags in sentences.keys()]\n",
    "sentence_probabilities = [sentence_count[sentence_tag]/total_count for sentence_tag in sentence_tags]\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    random_sentence_chose = np.random.multinomial(1, sentence_probabilities)\n",
    "    random_sentence_index = list(random_sentence_chose).index(1)\n",
    "    print(sentences[sentence_tags[random_sentence_index]].generate(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with that approach is that if the author uses a rich grammar (as it is the case of Lovecraft), not many phrases are gramatically repeated,\n",
    "so we get many unique tagged sentences as it happens here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18893 sentences are available and there are 18811 unique sentences (almost all)\n",
      "Sentences with more than one occurrence:\n",
      "DT-NNP: 8 times\n",
      "PRP-.: 8 times\n",
      "PRP: 8 times\n",
      "NN: 56 times\n",
      "DT-NNP-NNP-NNP-NNP: 8 times\n",
      "NNP-VBD-VBN-.: 3 times\n",
      "RB-DT-NN-VBD-.: 2 times\n",
      "PRP-VBD-DT-NN-.: 3 times\n",
      "DT-NN-VBD-RB-JJ-.: 2 times\n",
      "IN-NNP-NNP-NNP-NNP: 2 times\n",
      "DT-NN-.: 3 times\n",
      "DT-NNP-NNP-NNP-NNP-NNP: 3 times\n",
      ":-NN: 2 times\n",
      "DT-NNP-CC-DT-NNP-NNP-.: 3 times\n",
      "DT-NNP-CC-DT-NN: 4 times\n",
      "CD: 25 times\n",
      "NNP-.: 36 times\n",
      "PRP-VBD-:: 3 times\n",
      "NNP-VBD-RB-JJ-.: 2 times\n",
      "PRP-VBP-TO-PRP-VB-,-VB-RB-VB-RP-NNP-IN-PRP-MD-RB-VB-NNS-:-IN-DT-NNP-PRP-VBP-,-VBP-WDT-MD-IN-NNP-VB-RP-NNP-IN-PRP-,-VB-PRP$-NNP-NNPS-MD-RB-VB-IN-NN-.: 2 times\n",
      "NNP-IN-DT-NNP-,-IN-DT-NNP-MD-RB-VB-TO-NNP-,-CC-JJ-NN-JJR-IN-PRP-.: 2 times\n",
      "NNP-.-NNP-.: 3 times\n",
      "NNP: 4 times\n",
      "NNP-NNP-.: 6 times\n",
      "NN-.: 28 times\n",
      "NN-NNP-.: 5 times\n",
      "POS-NNP-.: 3 times\n",
      "CD-.: 2 times\n",
      "NNP-NN-.: 3 times\n",
      "EX-VBD-DT-NN-.: 2 times\n",
      "PRP-VBD-IN-VBZ-:: 2 times\n",
      "JJ-NNP-NN: 2 times\n",
      "UH-.: 2 times\n",
      "DT-VBZ-DT-.: 2 times\n",
      "DT-NNP-NNP: 9 times\n",
      "NNP-NN: 3 times\n",
      "DT-VBD-DT-.: 4 times\n",
      "JJ-NNP-.: 8 times\n",
      "CC-DT-VBD-DT-.: 2 times\n",
      "RB-RB-.: 2 times\n",
      "NNP-NNP: 4 times\n",
      "DT-NNP-NNP-NNP: 6 times\n",
      "DT-NNP-IN-NNP-NNP: 2 times\n",
      "JJ-NNP-POS-JJ-NN-POS-NN-NNP-NNP-POS-NN-NN-''-JJ-NN-NN: 2 times\n",
      "DT-VBZ-RB-JJ-WDT-MD-VB-NN-,-CC-IN-JJ-NNS-RB-NN-MD-VB-.: 2 times\n",
      "DT-NNP-IN-DT-NNP: 2 times\n",
      "PRP-MD-VB-PRP-.: 3 times\n",
      "VB-PRP-.: 2 times\n",
      "NNP-:-NN-.: 10 times\n",
      "DT-NNP-IN-DT-NNP-NNP-NN: 2 times\n",
      "PRP-VBP-PRP-.: 2 times\n",
      "NN-CD: 5 times\n",
      "NN-NNP: 3 times\n",
      "JJ-IN-NN-.: 2 times\n",
      "RB-PRP-VBD-.: 3 times\n",
      "RB-VBD-DT-JJ-NN-.: 2 times\n",
      "NNP-,-NN-.: 5 times\n",
      "JJ-NN-.: 5 times\n",
      "DT-NNP-IN-DT-NNP-NNP-.: 2 times\n",
      "DT-NNP-IN-DT-NNS: 2 times\n",
      "NNP-POS-NNP-NNP: 2 times\n",
      "PRP-VBD-.: 5 times\n",
      "NNP-POS-NN-NN-''-JJ-NN-NN-''-NN-.: 2 times\n",
      "DT-NN-''-NN-.: 2 times\n",
      "JJ-CD-:-CD-NNP-.-NNP-.: 2 times\n",
      "NN-NNP-:-NN-.: 2 times\n",
      "NNP-:-NN-NN: 6 times\n",
      "DT-NN: 3 times\n",
      "NNP-VBD-PRP-.: 2 times\n",
      "NNS: 2 times\n",
      "IN-PRP-.: 2 times\n",
      "CD-,-DT-.: 5 times\n",
      "VBN-NNP-CD-IN-NNP-NNP-NNP-.: 4 times\n",
      "CD-,-NN-.-CD-:-CD-.: 3 times\n",
      "NN-NNP-:-DT-NNP-IN-DT-NNP: 2 times\n",
      "POS-NNP-NN-CC-NN-IN-NN-,-NN-WP-VBP-IN-DT-NN-IN-NNS-CC-JJ-NN-,-WP-JJS-IN-DT-NN-IN-NNS-IN-DT-NNS-,-WP-JJS-IN-NN-CC-JJS-NN-TO-NNS-,-NNP-,-NNP-,-NN-RB-IN-PRP$-NNS-VBP: 2 times\n",
      "PRP$-JJ-NNP-:: 2 times\n",
      "(-DT-NNP-NNP-IN-NNP-NNP-): 2 times\n",
      "(-NNP-NNP-): 3 times\n",
      "NNP-:-NNP: 2 times\n",
      "(-NNP-NNP-NNP-): 2 times\n",
      "(-NNP-): 2 times\n"
     ]
    }
   ],
   "source": [
    "print(\"{} sentences are available and there are {} unique sentences (almost all)\".format(len(sentences), len([s for s, c in sentence_count.items() if c == 1])))\n",
    "\n",
    "print(\"Sentences with more than one occurrence:\")\n",
    "for cs, count in sentence_count.items():\n",
    "    if count > 1:\n",
    "        print(\"{}: {} times\".format(cs, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
